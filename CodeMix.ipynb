{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodeMix.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMx9QAIlWFyPJHKncuZz9hv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrymkwn/hackinutu/blob/main/CodeMix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PQ95KnENczx"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdA54OJXKwWw"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "import emoji\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Attention\n",
        "from tensorflow.keras.layers import Flatten, Dropout, Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.preprocessing\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjwsYJ-zilrC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTHnalLSOAT_",
        "outputId": "6339acc3-5738-444e-c47a-64260ebe5a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gkynYopNybS"
      },
      "source": [
        "#Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyFJdtr0VmN4",
        "outputId": "aebdd84b-41a5-45d6-9021-7a6093884cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train = pd.read_csv('/content/gdrive/My Drive/InfluenceAnalysis/CodeMix/Hinglish/hinglish-train.csv')\n",
        "df_test = pd.read_csv('/content/gdrive/My Drive/InfluenceAnalysis/CodeMix/Hinglish/hinglish-test.csv')\n",
        "df_dev = pd.read_csv('/content/gdrive/My Drive/InfluenceAnalysis/CodeMix/Hinglish/hinglish-dev.csv')\n",
        "\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uids</th>\n",
              "      <th>tokens</th>\n",
              "      <th>labels</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4330</td>\n",
              "      <td>['nen', 'Ã¡', 'vist', 'bolest', 'vztek', 'smute...</td>\n",
              "      <td>['Eng', 'O', 'Eng', 'Eng', 'Eng', 'Eng', 'Hin'...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41616</td>\n",
              "      <td>['@', 'nehantics', 'Haan', 'yaar', 'neha', 'ðŸ˜”ðŸ˜”...</td>\n",
              "      <td>['O', 'Hin', 'Hin', 'Hin', 'Hin', 'O', 'Hin', ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6648</td>\n",
              "      <td>['@', 'RahulGandhi', 'television', 'media', 'c...</td>\n",
              "      <td>['O', 'Eng', 'Eng', 'Eng', 'Eng', 'Hin', 'Hin'...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2512</td>\n",
              "      <td>['@', 'AmitShah', '@', 'narendramodi', 'All', ...</td>\n",
              "      <td>['O', 'Hin', 'O', 'Hin', 'Hin', 'Hin', 'Eng', ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>610</td>\n",
              "      <td>['@', 'Nehr', '_', 'who', '@', 'TypoMantri', '...</td>\n",
              "      <td>['O', 'Eng', 'O', 'Eng', 'O', 'Hin', 'O', 'Hin...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    uids  ... sentiment\n",
              "0   4330  ...   neutral\n",
              "1  41616  ...   neutral\n",
              "2   6648  ...  negative\n",
              "3   2512  ...  positive\n",
              "4    610  ...   neutral\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6h1sTmHULE9"
      },
      "source": [
        "def load_dict_smileys():\n",
        "    return {\n",
        "        \":â€‘)\":\"smiley\",\n",
        "        \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":â€‘D\":\"smiley\",\n",
        "        \"8â€‘D\":\"smiley\",\n",
        "        \"xâ€‘D\":\"smiley\",\n",
        "        \"Xâ€‘D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":â€‘(\":\"sad\",\n",
        "        \":â€‘c\":\"sad\",\n",
        "        \":â€‘<\":\"sad\",\n",
        "        \":â€‘[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'â€‘(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":â€‘P\":\"playful\",\n",
        "        \"Xâ€‘P\":\"playful\",\n",
        "        \"xâ€‘p\":\"playful\",\n",
        "        \":â€‘p\":\"playful\",\n",
        "        \":â€‘Ãž\":\"playful\",\n",
        "        \":â€‘Ã¾\":\"playful\",\n",
        "        \":â€‘b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Ãž\":\"playful\",\n",
        "        \":Ã¾\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n",
        "\n",
        "# source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "def load_dict_contractions():\n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }\n",
        "\n",
        "\n",
        "def tweet_cleaning_for_sentiment_analysis(tweet):\n",
        "    # lower case\n",
        "    tweet = tweet.lower()\n",
        "        \n",
        "    # replace contractions\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"â€™\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    \n",
        "    # standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    \n",
        "    # replace emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    \n",
        "    # demojize emojis\n",
        "    tweet = emoji.demojize(tweet)\n",
        "    \n",
        "    # other cleaning\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "    # replace duplicate characters\n",
        "    tweet = re.sub(r\"(.)\\1{2,}\", r'\\1\\1', tweet)\n",
        "\n",
        "    return tweet\n",
        "\n",
        "def clean(t,l):\n",
        "    for i in range(len(t)):\n",
        "        temp = tweet_cleaning_for_sentiment_analysis(' '.join(t[i])).split(' ')\n",
        "        t[i] = []\n",
        "        j=0\n",
        "        while j<len(temp):\n",
        "            t[i].append(temp[j])\n",
        "            j+=1\n",
        "        \n",
        "    return t, l"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qixzuZzWxKK",
        "outputId": "6e94c76b-bf22-4e1f-9ca0-104e38687cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uids</th>\n",
              "      <th>tokens</th>\n",
              "      <th>labels</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4330</td>\n",
              "      <td>['nen', 'Ã¡', 'vist', 'bolest', 'vztek', 'smute...</td>\n",
              "      <td>['Eng', 'O', 'Eng', 'Eng', 'Eng', 'Eng', 'Hin'...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41616</td>\n",
              "      <td>['@', 'nehantics', 'Haan', 'yaar', 'neha', 'ðŸ˜”ðŸ˜”...</td>\n",
              "      <td>['O', 'Hin', 'Hin', 'Hin', 'Hin', 'O', 'Hin', ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6648</td>\n",
              "      <td>['@', 'RahulGandhi', 'television', 'media', 'c...</td>\n",
              "      <td>['O', 'Eng', 'Eng', 'Eng', 'Eng', 'Hin', 'Hin'...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2512</td>\n",
              "      <td>['@', 'AmitShah', '@', 'narendramodi', 'All', ...</td>\n",
              "      <td>['O', 'Hin', 'O', 'Hin', 'Hin', 'Hin', 'Eng', ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>610</td>\n",
              "      <td>['@', 'Nehr', '_', 'who', '@', 'TypoMantri', '...</td>\n",
              "      <td>['O', 'Eng', 'O', 'Eng', 'O', 'Hin', 'O', 'Hin...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    uids  ... sentiment\n",
              "0   4330  ...   neutral\n",
              "1  41616  ...   neutral\n",
              "2   6648  ...  negative\n",
              "3   2512  ...  positive\n",
              "4    610  ...   neutral\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6snYi_dWhaV",
        "outputId": "0e84ea3b-a715-41e1-acfc-26c8ee82d0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train['tokens'] = df_train['tokens'].apply(lambda tweet : tweet_cleaning_for_sentiment_analysis(tweet))\n",
        "df_test['tokens'] = df_test['tokens'].apply(lambda tweet : tweet_cleaning_for_sentiment_analysis(tweet))\n",
        "df_dev['tokens'] = df_dev['tokens'].apply(lambda tweet : tweet_cleaning_for_sentiment_analysis(tweet))\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uids</th>\n",
              "      <th>tokens</th>\n",
              "      <th>labels</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4330</td>\n",
              "      <td>['nen', 'Ã¡', 'vist', 'bolest', 'vztek', 'smute...</td>\n",
              "      <td>['Eng', 'O', 'Eng', 'Eng', 'Eng', 'Eng', 'Hin'...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41616</td>\n",
              "      <td>['@', 'nehantics', 'haan', 'yaar', 'neha', ' p...</td>\n",
              "      <td>['O', 'Hin', 'Hin', 'Hin', 'Hin', 'O', 'Hin', ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6648</td>\n",
              "      <td>['@', 'rahulgandhi', 'television', 'media', 'c...</td>\n",
              "      <td>['O', 'Eng', 'Eng', 'Eng', 'Eng', 'Hin', 'Hin'...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2512</td>\n",
              "      <td>['@', 'amitshah', '@', 'narendramodi', 'all', ...</td>\n",
              "      <td>['O', 'Hin', 'O', 'Hin', 'Hin', 'Hin', 'Eng', ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>610</td>\n",
              "      <td>['@', 'nehr', '_', 'who', '@', 'typomantri', '...</td>\n",
              "      <td>['O', 'Eng', 'O', 'Eng', 'O', 'Hin', 'O', 'Hin...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    uids  ... sentiment\n",
              "0   4330  ...   neutral\n",
              "1  41616  ...   neutral\n",
              "2   6648  ...  negative\n",
              "3   2512  ...  positive\n",
              "4    610  ...   neutral\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7sF_C8KXLyl"
      },
      "source": [
        "def to_list(df):\n",
        "  return list(df['uids']),list(df['tokens']),list(df['labels']),list(df['sentiment']),len(list(df['sentiment']))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hdlA4cLYleY"
      },
      "source": [
        "u_train, t_train, l_train, s_train, max_length = to_list(df_train)\n",
        "u_dev, t_dev, l_dev, s_dev, max_length_dev = to_list(df_dev)\n",
        "u_test, t_test, l_test, s_test, max_length_test = to_list(df_test)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7CQmRmBY3Sn",
        "outputId": "f771f025-b1ca-4edd-8baf-f467c194736f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "tok_w = Tokenizer(char_level=False,lower=True,oov_token='UNK' )\n",
        "tok_w.fit_on_texts(t_train) \n",
        "\n",
        "MAX_LEN = 60\n",
        "trainInput_w = pad_sequences(tok_w.texts_to_sequences(t_train),\n",
        "                          maxlen=MAX_LEN, padding=\"post\")\n",
        "\n",
        "print(trainInput_w[10])\n",
        "valInput_w = pad_sequences(tok_w.texts_to_sequences(t_dev) ,\n",
        "                          maxlen=MAX_LEN, padding=\"post\")\n",
        "testInput_w = pad_sequences(tok_w.texts_to_sequences(t_test),\n",
        "                          maxlen=MAX_LEN, padding=\"post\")"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   2    2 3388  165   18 2123 9780 3828   74 1579  876    2    2  111\n",
            "  183 4362    2    2    2    2 9781    8   31  110 9782    7    5    2\n",
            "    2    4    2    2    6    2    2 9783    3    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mTE5QETi5PU",
        "outputId": "41c99b03-a3ba-45e8-eb47-a15c4944e333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxval =0\n",
        "\n",
        "for i in trainInput_w:\n",
        "  for num in i:\n",
        "    if maxval < num:\n",
        "      maxval = num\n",
        "\n",
        "print(maxval)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIft9i22ZICe"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(s_train)\n",
        "trainLabels = to_categorical(le.transform(s_train))\n",
        "valLabels = to_categorical(le.transform(s_dev))\n",
        "\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FruuFFB_iq1N",
        "outputId": "3421408c-bd36-4396-acab-724c2188d67f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
        "label_binarizer.fit(range(maxval)+1)\n",
        "for i in trainInput_w:\n",
        "  a = label_binarizer.transform(trainInput_w)\n",
        "  print(a)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-a4259bb242e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabel_binarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabel_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainInput_w\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'range' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdYgEs9VZRpX"
      },
      "source": [
        "#classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzyNxmEzZVCE"
      },
      "source": [
        "max_features = len(tok_w.word_index)\n",
        "maxlen = 60\n",
        "embedding_size = 100\n",
        "\n",
        "# Convolution\n",
        "kernel_size = 5\n",
        "filters = 128\n",
        "pool_size = 4\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSm1T4JJZP84"
      },
      "source": [
        "def generate_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features+1, embedding_size, input_length=maxlen))\n",
        "  model.add(Conv1D(filters,kernel_size,padding='valid',activation='relu',strides=1))\n",
        "  model.add(MaxPooling1D(pool_size=pool_size))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_fP7CUJZ73q"
      },
      "source": [
        "def generate_lstm():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features+1, embedding_size, input_length=maxlen))\n",
        "  model.add(LSTM(embedding_size))\n",
        "  model.add(Dense(10,activation='relu'))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB5RXbeBZch_",
        "outputId": "85a56403-bc6f-4483-f2bd-e97c744253cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = generate_model()\n",
        "type(model)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_22 (Embedding)     (None, 60, 100)           4882400   \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 56, 128)           64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling (None, 14, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 3)                 5379      \n",
            "=================================================================\n",
            "Total params: 4,951,907\n",
            "Trainable params: 4,951,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.engine.sequential.Sequential"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qrZGYDxZheh",
        "outputId": "6fe821ad-600c-46fc-e195-1b6b3c7a9a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.fit(trainInput_w, trainLabels,batch_size=32,validation_data=(valInput_w,valLabels),epochs=5)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "438/438 [==============================] - 32s 74ms/step - loss: 0.9371 - accuracy: 0.5206 - val_loss: 0.8492 - val_accuracy: 0.6003\n",
            "Epoch 2/5\n",
            "438/438 [==============================] - 32s 74ms/step - loss: 0.5863 - accuracy: 0.7636 - val_loss: 0.9319 - val_accuracy: 0.5933\n",
            "Epoch 3/5\n",
            "438/438 [==============================] - 32s 74ms/step - loss: 0.1558 - accuracy: 0.9546 - val_loss: 1.2155 - val_accuracy: 0.5577\n",
            "Epoch 4/5\n",
            "438/438 [==============================] - 33s 75ms/step - loss: 0.0451 - accuracy: 0.9889 - val_loss: 1.3374 - val_accuracy: 0.5533\n",
            "Epoch 5/5\n",
            "438/438 [==============================] - 32s 74ms/step - loss: 0.0272 - accuracy: 0.9935 - val_loss: 1.4072 - val_accuracy: 0.5543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90d13a36a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYZn0e0Hg4aL",
        "outputId": "35773ed6-d486-45bc-bbfb-40773c3f0d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "lstm = generate_lstm()\n",
        "type(lstm)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_23 (Embedding)     (None, 60, 100)           4882400   \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 4,963,843\n",
            "Trainable params: 4,963,843\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.engine.sequential.Sequential"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuqO8i8Jg_BX",
        "outputId": "17eaa0d5-3377-4816-d404-f27f356a5048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "lstm.fit(trainInput_w, trainLabels,batch_size=32,validation_data=(valInput_w,valLabels),epochs=5)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "438/438 [==============================] - 47s 106ms/step - loss: 1.0945 - accuracy: 0.3754 - val_loss: 1.0943 - val_accuracy: 0.3760\n",
            "Epoch 2/5\n",
            "438/438 [==============================] - 45s 103ms/step - loss: 1.0904 - accuracy: 0.3822 - val_loss: 1.0879 - val_accuracy: 0.3803\n",
            "Epoch 3/5\n",
            "438/438 [==============================] - 45s 103ms/step - loss: 1.0859 - accuracy: 0.3856 - val_loss: 1.0868 - val_accuracy: 0.3807\n",
            "Epoch 4/5\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 1.0856 - accuracy: 0.3860 - val_loss: 1.0885 - val_accuracy: 0.3797\n",
            "Epoch 5/5\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 1.0842 - accuracy: 0.3869 - val_loss: 1.0873 - val_accuracy: 0.3810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90d114efd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_J86XIaZqMO"
      },
      "source": [
        "predictions = model.predict(testInput_w)\n",
        "predictions = np.argmax(predictions,axis=-1)\n",
        "\n",
        "# write predictions to file\n",
        "with open('preds.txt', 'w') as out:\n",
        "    out.write('Uid,Sentiment')\n",
        "    for i, uid in enumerate(u_test):\n",
        "        if predictions[i] == 0:\n",
        "            sentiment = 'negative'\n",
        "        elif predictions[i] == 1:\n",
        "            sentiment = 'neutral'\n",
        "        else:\n",
        "            sentiment = 'positive'\n",
        "        out.write(\"\\n%s,%s\"%(uid, sentiment))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIQcT5t4ZtN5"
      },
      "source": [
        "# load correct labels\n",
        "test = pd.read_csv('Hinglish_test_labels.txt')\n",
        "# load predictions\n",
        "preds = pd.read_csv('preds.txt')\n",
        "\n",
        "# compute evaluation metrics\n",
        "results = {'preds': classification_report(test['Sentiment'], preds['Sentiment'], labels=['positive', 'neutral', 'negative'], output_dict=True, digits=6)}"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9c0dluzZwNM",
        "outputId": "39f21c4e-94a8-4381-9393-e26155b71112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# format and print scores\n",
        "formatted_results = [['model', 'precision', 'recall', 'accuracy', 'f1-score']]\n",
        "for ki in results.keys():\n",
        "    scores = results[ki]['macro avg']\n",
        "    model = [ki, scores['precision'], scores['recall'], results[ki]['accuracy'], scores['f1-score']]\n",
        "    formatted_results.append(model)\n",
        "    \n",
        "formatted_results = pd.DataFrame(formatted_results[1:], columns=formatted_results[0])\n",
        "print(formatted_results)\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   model  precision    recall  accuracy  f1-score\n",
            "0  preds   0.450229  0.457347      0.44  0.426156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBhAejXjZwhj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}